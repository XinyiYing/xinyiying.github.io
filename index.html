<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
	<style>
		body{
			color: #333;
		}
		#container{
			min-width: 1000px;
			width: 1000px;
/*			overflow: auto;
*/			margin: 50px auto;padding: 30px;
			/*zoom: 1;*/
*//*			border: 1px solid #ccc;background: #fc9;color: #fff;
*/		}
		#left{
			float: left;
			width: 230px;
			height: 250px;
			margin-left: 0px;
		}
		#right{
			float: left;
			width: auto;
			margin-left: 30px;
		}
		#name{
			font-size: 22.0pt;
		    mso-bidi-font-size: 24.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		        font-weight: bold;
		}
		#info{
		    font-size: 16.0pt;
		    mso-bidi-font-size: 16.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 30px;
		    margin-left: 5px;
		    margin-bottom: 10px;
		    
		}
		.clear{clear:both; height: 0; line-height: 0; font-size: 0}
		.Bio{
			font-size:16.0pt;
			mso-bidi-font-size:17.0pt;
			line-height:150%;
			font-family:Times;
			mso-bidi-font-family:Lato-Regular;
			text-align: justify;
		}
		span.SpellE {
		    mso-style-name: "";
		    mso-spl-e: yes;
		}
		span.Title{
			    font-size: 22.0pt;
			    mso-bidi-font-size: 17.0pt;
			    font-family: Times;
			    mso-bidi-font-family: Lato-Regular;
			    font: bold;
			    margin-top: 10px;
			    width: 1000px;
		}
		div.section{
			padding-top: 30px;
		}
		
		div.sub-left{
			float: left;
			width: 250px;
						
		}
		div.sub-left img{
			vertical-align: middle;
			horizontal-align: middle;
			margin-top: 10px;
		}
		
		div.sub-left span{
			height: 100%;
			display: inline-block;
			vertical-align: top;
						
		}
		div.sub-right{
			float: left;
			width: 750px;			
		}
		.paper{
			overflow: auto;
			zoom:1;
			border-top: 2px ;
			padding-bottom: 0px;
			min-height: 160px;

		}
		.paperTitle{
			font-size:14pt;
			mso-bidi-font-size:14pt;
			font-family:Calibri;
			mso-bidi-font-family:Calibri;
			margin-top: 10px;
			margin-bottom: 5px;
			font-weight: bold;
		}
		.paperName{
		    font-size: 12pt;
		    mso-bidi-font-size: 12pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;
		    line-height:160%;
		    font-style: italic;
		}		
		.paperPub{
		    font-size: 14pt;
		    mso-bidi-font-size: 14pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;		    
		    font-style: italic;
		    line-height:160%;
		}
		.paperLink{
		    font-size: 13.0pt;
		    mso-bidi-font-size: 13.0pt;		    
		    font-family: Calibri;
		    mso-bidi-font-family: Times;
		    line-height:170%;
		}
		.special{
		    margin-top: 0in;
		    margin-bottom: 0in;
		    margin-left: -.9pt;
		    margin-bottom: .0001pt;
		    text-indent: .9pt;
		    mso-pagination: none;
		    tab-stops: 13.75in;
		    mso-layout-grid-align: none;
		    text-autospace: none;
		}
		.long div.sub-left, .long div.sub-right{
			height: 300px;
			width: 980px;

		}
		.short div.sub-left, .short div.sub-right{
			height:150px;

		}
		div.sub-left,div.sub-right{
			height:200px;

		}
	</style>
</head>
<body>
	<div id="container">
		<div id="left">			
			<img width="200" height="230" src="imgs/photo5.jpg">
		</div>
		<div id="right">
			<div id="name">Xinyi Ying (应昕怡) </div>
			<div id="info">

				Ph.D Candidate<p>
				National University of Defense Technology (NUDT)<p>
				Email: yingxinyi18@nudt.edu.cn<p>				
			</div>
			         <a href="https://www.researchgate.net/profile/Xinyi-Ying" target="_blank" rel="nofollow"><span>Research Gate</span></a>  |
			         <a href="https://github.com/XinyiYing" target="_blank" rel="nofollow"><span>Github</span></a>  |
				 <a href="https://scholar.google.cz/citations?user=45ifNRkAAAAJ&hl=zh-CN" target="_blank" rel="nofollow"><span>Google Scholar</span></a>  
			
			</div>

		<div class="clear"></div>
		<div class="section">
			<span class="Title"><b>Brief Bio</b></span><p>			
				<div class="Bio">
					I received my Master degree from Master degrees from NUDT in 2018. Currently, I'm a PHD student with the College of Electronic Science and Technology, NUDT. My research interests focus on optical imaging and detection, particularly on
					<b style="mso-bidi-font-weight:normal">infrared small target detection</b> and <b style="mso-bidi-font-weight:normal">weakly supervised semantic segmentation</b>.</span></p>
				</div>


	<!-- <div class="section">
		<span class="Title"><b>News</b></span><p>
		<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		<div class="paper long"><b>
			<div class="sub-right">
			<div class="paperName"><b>	
			2024.03 | Our paper "Real-World Light Field Image Super-Resolution via Degradation Modulation" is accepted by <span style="color:red">IEEE TNNLS</span>.<br>
			2024.02 | Our paper "Learning Coupled Dictionaries from Unpaired Data for Image Super-Resolution" is accepted to <span style="color:red">CVPR 2024</span>.<br>
			2023.11 | One paper on multi-frame infrared small target detection is accepted to <span style="color:red">IEEE TNNLS</span>.<br>
			2023.09 | Four papers are selected as <span style="color:red">Highly Cited Papers</span> in the latest issue of ESI Index.<br>
			2023.07 | Two papers on light field image super-resolution and pointly supervised infrared small target detection are accepted to <span style="color:red">ICCV 2023</span>.<br>
			2023.02 | One paper on pointly supervised infrared small target detection is accepted to <span style="color:red">CVPR 2023</span>.<br>
			2023.01 | We are organizing <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2023" target="_blank" rel="nofollow">NTIRE Stereo Image SR Challenge</a> and <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/LF-Image-SR/tree/NTIRE2023" target="_blank" rel="nofollow">NTIRE LF Image SR Challenge</a> at CVPR 2023.<br>	
			2022.07 | Our paper "Dense Nested Attention Network for Infrared Small Target Detection" is accepted by <span style="color:red">IEEE TIP</span>. <br>
			2022.07 | Our paper "Exploring Fine-Grained Sparsity in Convolutional Neural Networks for Efficient Inference" is accepted by <span style="color:red">IEEE TPAMI</span>.<br>
			2022.03 | Two papers on network quantization and light field depth estimation are accepted to <span style="color:red">CVPR 2022</span>.<br>
			2022.02 | Our paper "Disentangling Light Fields for Super-Resolution and Disparity Estimation" is accepted by <span style="color:red">IEEE TPAMI</span>.<br>
			2022.01 | We are organizing <a href="https://github.com/The-Learning-And-Vision-Atelier-LAVA/Stereo-Image-SR/tree/NTIRE2022" target="_blank" rel="nofollow">NTIRE Stereo Image Super-Resolution Challenge</a> at CVPR 2022.<br> 
			2021.10 | Our paper "Dense Dual-Attention Network for Light Field Image Super-Resolution" is accepted by IEEE TCSVT. [<a href="https://arxiv.org/pdf/2110.12114.pdf" target="_blank" rel="nofollow">pdf</a>]<br>				
			2021.10 | Our paper "Spatial-Angular Attention Network for Light Field Reconstruction" is accepted by <span style="color:red">IEEE TIP</span>. <br>	
			2021.07 | Our paper "Learning a Single Network for Scale-Arbitrary Super-Resolution" is accepted to <span style="color:red">ICCV 2021</span>.<br>
			2021.03 | Two papers on single image super-resolution are accepted to <span style="color:red">CVPR 2021</span>.<br>
			2020.11 | Our paper "Light Field Image Super-Resolution Using Deformable Convolution" is accepted by <span style="color:red">IEEE TIP</span>.<br>
			2020.09 | An online tutorial (120 min in Chinese) regarding our Parallax Attention Mechanism is available <a href="https://www.shenlanxueyuan.com/open/course/77" target="_blank" rel="nofollow">here</a>.<br>
			2020.09 | Our paper "Parallax Attention for Unsupervised Stereo Correspondence Learning" is accepted by <span style="color:red">IEEE TPAMI</span>.<br>
			2020.07 | Our paper "Spatial-Angular Interaction for Light Field Image Super-Resolution" is accepted to <span style="color:red">ECCV 2020</span>.<br>	
			2019.12 | Our paper "DeOccNet: Learning to See Through Foreground Occlusions in Light Fields" is accepted to WACV 2020.<br>
			2019.03 | A large-scale dataset for stereo image super-resolution is available online at <a href="https://yingqianwang.github.io/Flickr1024" target="_blank" rel="nofollow">Flickr1024</a>. <br>
			2019.02 | Our paper "Learning Parallax Attention for Stereo Image Super-Resolution" is accepted to <span style="color:red">CVPR 2019</span>.<br><br>
			</b></div>
			</b></div>
		</b></div>
	</div> -->
	
	
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2024</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/OBBInst.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						OBBInst: Remote sensing instance segmentation with oriented bounding box supervision
					</div>
					<div class="paperName">
						Xu Cao, Huanxin Zou, Jun Li, <b>Xinyi Ying</b>, Shitian He
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>JAG</b></span>, 2024.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://www.sciencedirect.com/science/article/pii/S1569843224000712" target="_blank" rel="nofollow">Paper</a>							
					</div>
				</div>
			</div>	
	
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2023</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/LESPS.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Mapping degeneration meets label evolution: Learning infrared small target detection with single point supervision
					</div>
					<div class="paperName">
						<b>Xinyi Ying</b>, Li Liu, Yingqian Wang, Ruojing Li, Nuo Chen, Zaiping Lin, Weidong Sheng, Shilin Zhou
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>CVPR</b></span>, 2023.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ying_Mapping_Degeneration_Meets_Label_Evolution_Learning_Infrared_Small_Target_Detection_CVPR_2023_paper.pdf" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ying_Mapping_Degeneration_Meets_CVPR_2023_supplemental.pdf" target="_blank" rel="nofollow">Supp</a>
						| <a href="https://xinyiying.github.io/LESPS/" target="_blank" rel="nofollow">Webpage</a>						
						| <a href="https://github.com/XinyiYing/LESPS" target="_blank" rel="nofollow">Code</a>	
					</div>
				</div>
			</div>
		
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/SDF.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Learning scalable dynamic filter in convolutional networks
					</div>
					<div class="paperName">
						Shuanglin Wu, Chao Xiao, <b>Xinyi Ying</b>, Longguang Wang, Jungang Yang, Wei An
					</div>
					<div class="paperPub">
						<span style="color:rgb(0, 0, 0)"> <b>IEEE PRL</b></span>, 2023.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://www.sciencedirect.com/science/article/abs/pii/S016786552300291X" target="_blank" rel="nofollow">Paper</a>							
					</div>
				</div>
			</div>
		
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2022</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
		
		
	<div class="paper short">
		<div class="sub-left">
			<span></span>
			<img border="0" width="200" height="130" src="imgs/SMCNN.png">
		</div>
		<div class="sub-right">
			<div class="paperTitle">
				Exploring Fine-Grained Sparsity in Convolutional Neural Networks for Efficient Inference
			</div>
			<div class="paperName">
				Longguang Wang, Yulan Guo, Xiaoyu Dong, Yingqian Wang, <b>Xinyi Ying</b>, Zaiping Lin, Wei An
			</div>
			<div class="paperPub">
				<span style="color:red"> <b>IEEE TPAMI</b></span>, 2022.<br>
			</div>
			<div class="paperLink">
				| <a href="https://ieeexplore.ieee.org/document/9841044" target="_blank" rel="nofollow">Paper</a>						
				| <a href="https://github.com/LongguangWang/SparseMask" target="_blank" rel="nofollow">Code</a>						
			</div>
		</div>
	</div> 

	<div class="paper short">
			<div class="sub-left">
				<span></span>
				<img border="0" width="200" height="130" src="imgs/MoCoPnet.jpg">
			</div>
			<div class="sub-right">
				<div class="paperTitle">
					Local Motion and Contrast Priors Driven Deep Network for Infrared Small Target Super-resolution
				</div>
				<div class="paperName">
					<b>Xinyi Ying</b>, Yingqian Wang, Longguang Wang, Weidong Sheng, Li Liu, Zaiping Lin, Shilin Zhou
				</div>
				<div class="paperPub">
					<span style="color:rgb(0, 0, 0)"> <b>JSTAR</b></span>, 2022.<br>
				</div>
				<div class="paperLink">
					| <a href="https://arxiv.org/pdf/2201.01014" target="_blank" rel="nofollow">Paper</a>
					| <a href="https://github.com/XinyiYing/MoCoPnet" target="_blank" rel="nofollow">Code</a>	
				</div>
			</div>
		</div>

	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2021</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
			
	<div class="paper short">
		<div class="sub-left">
			<span></span>
			<img border="0" width="200" height="130" src="imgs/SMSR.png">
		</div>
		<div class="sub-right">
			<div class="paperTitle">
				Exploring Sparsity in Image Super-Resolution for Efficient Inference
			</div>
			<div class="paperName">
				Longguang Wang, Xiaoyu Dong, Yingqian Wang, <b>Xinyi Ying</b>, Zaiping Lin, Wei An, Yulan Guo
			</div>
			<div class="paperPub">
				<span style="color:red"> <b>CVPR</b></span>, 2021.<br> 
			</div>
			<div class="paperLink">
				| <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Exploring_Sparsity_in_Image_Super-Resolution_for_Efficient_Inference_CVPR_2021_paper.pdf" target="_blank" rel="nofollow">Paper</a>
				| <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_Exploring_Sparsity_in_CVPR_2021_supplemental.pdf" target="_blank" rel="nofollow">Supp</a>
				| <a href="https://mp.weixin.qq.com/s/vIacjZk6UvNCxJIdBWY0og" target="_blank" rel="nofollow">News</a>
				| <a href="https://www.bilibili.com/video/BV1eL411x7sy?spm_id_from=333.999.0.0" target="_blank" rel="nofollow">Video Presentation</a>
				| <a href="https://github.com/LongguangWang/SMSR" target="_blank" rel="nofollow">Code</a>						
			</div>
		</div>
	</div>	

	<div class="paper short">
		<div class="sub-left">
			<span></span>
			<img border="0" width="200" height="130" src="imgs/Symmetric.jpg">
		</div>
		<div class="sub-right">
			<div class="paperTitle">
				Symmetric parallax attention for stereo image super-resolution
			</div>
			<div class="paperName">
				Yingqian Wang, <b>Xinyi Ying</b>, Longguang Wang, Jungang Yang, Wei An, Yulan Guo
			</div>
			<div class="paperPub">
				<span style="color:red"> <b>CVPRW</b></span>, 2022.<br>
			</div>
			<div class="paperLink">
				| <a href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Wang_Symmetric_Parallax_Attention_for_Stereo_Image_Super-Resolution_CVPRW_2021_paper.pdf" target="_blank" rel="nofollow">Paper</a>
				| <a href="https://github.com/YingqianWang/iPASSR" target="_blank" rel="nofollow">Code</a>	
			</div>
		</div>
	</div>
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="imgs/DSFNet.jpg" width="200" height="130">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						DSFNet: Dynamic and static fusion network for moving object detection in satellite videos
					</div>
					<div class="paperName">
						Chao Xiao, Qian Yin, <b>Xinyi Ying</b>, Ruojing Li, Shuanglin Wu, Miao Li, Li Liu, Wei An, Zhijie Chen
					</div>
					<div class="paperPub">
						<span style="color:rgb(0, 0, 0)"> <b>GRSL</b></span>, 2021.<br> 
					</div>
					<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/abstract/document/9594855" target="_blank" rel="nofollow">Paper</a>												
					</div>
				</div>
			</div>
		
		
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/SAAN.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Channelmix: A mixed sample data augmentation strategy for image classification
					</div>
					<div class="paperName">
						Xu Cao, HuanXin Zou, <b>XinYi Ying</b>, RunLin Li, ShiTian He, Fei Cheng
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>CBFD</b></span>, 2021.<br>
					</div>
					<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/abstract/document/9408747/" target="_blank" rel="nofollow">Paper</a>					
					</div>
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/SAAN.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Double-triplet-pseudo-Siamese architecture for remote sensing aircraft target recognition
					</div>
					<div class="paperName">
						Xu Cao, HuanXin Zou, <b>XinYi Ying</b>, RunLin Li, ShiTian He, Fei Cheng
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>ICSP</b></span>, 2021.<br>
					</div>
					<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/abstract/document/9759163/" target="_blank" rel="nofollow">Paper</a>					
					</div>
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/SAAN.png">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Using Bilinear-Siamese architecture for remote sensing scene classification
					</div>
					<div class="paperName">
						Xu Cao, HuanXin Zou, <b>XinYi Ying</b>, RunLin Li, ShiTian He, Fei Cheng
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>AIID</b></span>, 2021.<br>
					</div>
					<div class="paperLink">
						| <a href="https://ieeexplore.ieee.org/abstract/document/9456523/" target="_blank" rel="nofollow">Paper</a>					
					</div>
				</div>
			</div>
	
	<div class="clear"></div>
	<div class="section">
	<span class="Title"><b>Publications --- 2020</b></span><p><p>
	<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		

	<div class="paper short">
		<div class="sub-left">
			<span></span>
			<img border="0" width="200" height="130" src="imgs/LF-DFnet.jpg">
		</div>
		<div class="sub-right">
			<div class="paperTitle">
				Light Field Image Super-Resolution Using Deformable Convolution
			</div>
			<div class="paperName">
				Yingqian Wang, Jungang Yang, Longguang Wang, <b>Xinyi Ying</b>, Tianhao Wu, Wei An, Yulan Guo
			</div>
			<div class="paperPub">
				<span style="color:red"> <b>IEEE TIP</b></span>, 2020.<br>
			</div>
			<div class="paperLink">
				| <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286855" target="_blank" rel="nofollow">Paper</a>						
				| <a href="https://github.com/YingqianWang/LF-DFnet" target="_blank" rel="nofollow">Code</a>						
			</div>
		</div>
	</div>
		
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img border="0" width="200" height="130" src="imgs/D3Dnet.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						Deformable 3d convolution for video super-resolution
					</div>
					<div class="paperName">
					<b>Xinyi Ying</b>, Longguang Wang, Yingqian Wang, Weidong Sheng, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>IEEE SPL</b></span>, 2020.<br>
					</div>
					<div class="paperLink">
						| <a href="https://arxiv.org/pdf/2004.02803" target="_blank" rel="nofollow">Paper</a>						
						| <a href="https://github.com/XinyiYing/D3Dnet" target="_blank" rel="nofollow">Code</a>						
					</div>
				</div>
			</div>
		
				
			<div class="paper short">
				<div class="sub-left">
					<span></span>					
					<img border="0" width="200" height="130" src="imgs/SAM.jpg">
				</div>
				<div class="sub-right">
					<div class="paperTitle">
						A stereo attention module for stereo image super-resolution
					</div>
					<div class="paperName">
						<b>Xinyi Ying</b>, Longguang Wang, Yingqian Wang, Weidong Sheng, Wei An, Yulan Guo
					</div>
					<div class="paperPub">
						<span style="color:red"> <b>IEEE SPL</b></span>, 2020.<br>
					</div>
					<div class="paperLink">
						| <a href="https://arxiv.org/pdf/2004.02803" target="_blank" rel="nofollow">Paper</a>
						| <a href="https://github.com/XinyiYing/SAM" target="_blank" rel="nofollow">News</a>					
					</div>
				</div>
			</div>	
		
<div class="section">
				<span class="Title"><b>Academic Services</b></span><p>
				<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
				<div class="paperName"><b>
					<!-- PC Members:<br>
					<a href="https://cvlai.net/ntire/2023/" target="_blank" rel="nofollow">New Trends in Image Restoration and Enhancement (NTIRE) Wokshop @ CVPR 2023</a>,	<br>				
					<a href="https://data.vision.ee.ethz.ch/cvl/aim22/" target="_blank" rel="nofollow">Advances in Image Manipulation (AIM) Workshop @ ECCV 2022</a>,<br>
					<a href="https://data.vision.ee.ethz.ch/cvl/ntire22/" target="_blank" rel="nofollow">New Trends in Image Restoration and Enhancement (NTIRE) Wokshop @ CVPR 2022</a>,<br>					
					<br> -->
					Challenge Organization:<br>
					<a href="http://prcv.cn/?competition_128/" target="_blank" rel="nofollow">Wide Area Infrared Small Target Detection Challenge @ PRCV 2024</a>,<br>
					<a href="" target="_blank" rel="nofollow">Resourse-Limited Infrared Small Target Detection Challenge @ ICPR 2024</a>,<br>
					<br>
					Reviewer:<br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76" target="_blank" rel="nofollow">IEEE Transactions on Circuits and Systems for Video Technology</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36" target="_blank" rel="nofollow">IEEE Transactions on Geoscience and Remote Sensing</a> <br>
					<a href="https://www.sciencedirect.com/journal/international-journal-of-applied-earth-observation-and-geoinformation?utm_campaign=STMJ_1636705839_SC&utm_medium=SRCH&utm_source=B&dgcid=STMJ_1636705839_SC" target="_blank" rel="nofollow">IEEE International Journal of Applied Earth Observation and Geoinformation</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36" target="_blank" rel="nofollow">IEEE Signal Processing Letter</a> <br>
					<a href="https://www.inns.org/wcci-2024-call-for-papers" target="_blank" rel="nofollow">IEEE International Joint Conference on Neural Networks</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/conhome/1000545/all-proceedings" target="_blank" rel="nofollow">IEEE International Conference on Pattern Recognition</a> <br>
					<a href="https://www.showsbee.com/fairs/86230-IEEE-ICIP-2024.html" target="_blank" rel="nofollow">IEEE International Conference on Image Processing</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36" target="_blank" rel="nofollow">IEEE Access</a> <br>
					<a href="https://www.scimagojr.com/journalsearch.php?q=24825&tip=sid" target="_blank" rel="nofollow">Pattern Recognition Letters</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36" target="_blank" rel="nofollow">IET Computer Vision</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36" target="_blank" rel="nofollow">IET Image Processing</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?reload=true&punumber=38" target="_blank" rel="nofollow">IEEE Computer Graphics and Applications</a> <br>
					<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36" target="_blank" rel="nofollow">Chinese Conference on Pattern Recognition and Computer Vision</a> <br>
					<a href="https://link.springer.com/journal/530/volumes-and-issues" target="_blank" rel="nofollow">Multimedia Systems</a> <br>
					<a href="https://www.aimspress.com/journal/MBE" target="_blank" rel="nofollow">
						Mathematical Biosciences and Engineering</a> 
					<br>					
					......<br>
					<br>
					</b></div>
			</div>		

			<div class="section">
				<span class="Title"><b>Teaching Assistance</b></span><p>
				<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
				<div class="paperName"><b>		
					Lecture: Signals and Systems (Spring Term, 2022)<br>
					Lecture: Signals and Systems (Autumn Term, 2021)<br>
					Lecture: Signals and Systems (Spring Term, 2020)<br>
					Lecture: Target Detection and Signal Processing (Autumn Term, 2019)<br>
					Lecture: Target Detection and Signal Processing (Autumn Term, 2018)
				</b></div>
			</div>
		
		
			
		

			<div class="section">
				<span class="Title"><b>Awards & Honors</b></span><p>
				<hr style="BORDER-LEFT-STYLE: none; BORDER-TOP: gray 2px groove; HEIGHT: 0px; BORDER-BOTTOM-STYLE: none; BORDER-RIGHT-STYLE: none">
		
				<div class="paperName"><b>
					2023 | Best Paper of China Society of Image and Graphics (LESPS CVPR)<br>
					2022 | Second-class Scholarship of NUDT<br>
					2022 | Outstanding Master Dissertation Award of NUDT<br>
					2022 | Outstanding Master Dissertation Award of NUDT<br>
					2022 | Excellent Student of NUDT<br>
					2021 | Excellent Student of NUDT
				</b></div>
			</div>		

			<!-- Last update time begjin -->
			<div style="border-top: 3px solid #555; text-align: center;">
				<p style="color: #555;">Last updated: 2024-04-14</p>
			</div>
			<!-- Last update time end -->

	</div>
	
</body>
</html>
